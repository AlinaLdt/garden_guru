import os
import requests
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import numpy as np
import openai

# Set Roboflow API key
roboflow_api_key = os.environ["ROBOFLOW_API_KEY"]

# Set OpenAI API key
openai_api_key = os.environ["OPENAI_API_KEY"]

# Initialize the OpenAI API client
openai.api_key = openai_api_key

# Roboflow Model URL
MODEL_ID = "houseplants-image-detection/1"
ROBOFLOW_URL = f"https://detect.roboflow.com/{MODEL_ID}?api_key={roboflow_api_key}"

from openai import OpenAI
client = OpenAI()

# Function to perform inference on a local image
def infer_local_image(image_path):
    #breakpoint()
    with open(image_path, "rb") as image_file:
        response = requests.post(ROBOFLOW_URL, files={"file": image_file})
    result = response.json()
    return result

# Function to get care tips using OpenAI GPT-3
def get_care_tips(plant_class):


    completion = client.chat.completions.create(
    model="gpt-3.5-turbo-16k",
    messages=[
    {"role": "system", "content": "You are in a role of plant expert."},
    {"role": "user", "content": f"Give me useful advice for taking care for this plant: {plant_class}"}
  ]
)

    return completion.choices[0].message.content

    #prompt = f"Plant: {plant_class}\nCare tips:"
    #response = openai.Completion.create(
    #    engine="davinci",
    #    prompt=prompt,
    #    max_tokens=100
    #)
    #care_tips = response.choices[0].text
    #return care_tips


# Function to draw bounding boxes on the image
# def draw_bbox(image_path, detections):
#     image = Image.open(image_path)
#     draw = ImageDraw.Draw(image)

#     for detection in detections:
#         bbox = detection["bbox"]
#         class_name = detection["class"]
#         confidence = detection["confidence"]
#         x, y, w, h = bbox["x"], bbox["y"], bbox["width"], bbox["height"]
#         left = x - w / 2
#         top = y - h / 2
#         right = x + w / 2
#         bottom = y + h / 2
#         draw.rectangle(((left, top), (right, bottom)), outline="red", width=2)
#         text = f"{class_name}: {confidence:.2f}"
#         draw.text((left, top), text, fill="red")

#     image.show()

# Example for local image
local_image_path = "raw_data/Begonia_rex.jpg"
local_result = infer_local_image(local_image_path)

# Get the class of the plant
if local_result['predictions']:
    plant_class = local_result['predictions'][0]['class']
    print(f"Detected plant class: {plant_class}")

    # Get care tips for the detected plant class
    care_tips = get_care_tips(plant_class)
    print(f"Care tips for {plant_class}: {care_tips}")

    # Draw bounding boxes on the image
    # draw_bbox(local_image_path, local_result['predictions'])

    # Display image with bounding box
    # img = np.asarray(Image.open(local_image_path))
    # plt.imshow(img)
    # plt.show()
else:
    print("No plants detected.")
